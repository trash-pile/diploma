{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f97f22-51a8-4956-bd53-36b8502aaa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting image stitching process from 3 to 21\n",
      "\n",
      "Processing image 4/20 [4.8s]\n",
      "\n",
      "Processing image 5/20 [5.5s]\n",
      "\n",
      "Processing image 6/20 [5.9s]\n",
      "\n",
      "Processing image 7/20 [6.6s]\n",
      "\n",
      "Processing image 8/20 [6.2s]\n",
      "\n",
      "Processing image 9/20 [6.2s]\n",
      "\n",
      "Processing image 10/20 [6.7s]\n",
      "\n",
      "Processing image 11/20 [6.5s]\n",
      "\n",
      "Processing image 12/20 [6.5s]\n",
      "\n",
      "Processing image 13/20 [6.4s]\n",
      "\n",
      "Processing image 14/20 [6.6s]\n",
      "\n",
      "Processing image 15/20 [6.9s]\n",
      "\n",
      "Processing image 16/20 [8.0s]\n",
      "\n",
      "Processing image 17/20 [8.1s]\n",
      "\n",
      "Processing image 18/20 [8.3s]\n",
      "\n",
      "Processing image 19/20 [8.3s]\n",
      "\n",
      "Processing image 20/20 [Saved result_20.png][9.2s]\n",
      "\n",
      "Stitching completed:\n",
      "Total images processed: 17/17 (0 failed)\n",
      "Total time: 117.0s (avg 6.9s per image)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from time import time\n",
    "from typing import Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    # Image processing parameters\n",
    "    SCALE: float = 0.25\n",
    "    WIDEN: int = 3000\n",
    "    SEARCH_WINDOW: int = 2000\n",
    "    OVERLAP_MARGIN: int = 500\n",
    "    \n",
    "    # Feature detection parameters\n",
    "    NFEAT: int = 100000\n",
    "    MATCH_RATIO: float = 0.7\n",
    "    KEEP_PERCENT: float = 0.75\n",
    "    THRESH: float = 250.0\n",
    "    MIN_INLIERS: float = 0.01\n",
    "\n",
    "class ImageStitcher:\n",
    "    def __init__(self, path: str = \"./folder2/\"):\n",
    "        self.path = Path(path)\n",
    "        self.sift = cv2.SIFT_create(nfeatures=Config.NFEAT)\n",
    "        self.matcher = cv2.FlannBasedMatcher(\n",
    "            dict(algorithm=1, trees=5),\n",
    "            dict(checks=50)\n",
    "        )\n",
    "        self.last_match_region: Optional[Tuple[int, int]] = None\n",
    "        \n",
    "        # Pre-allocate reusable buffers\n",
    "        self._gray_buffer1: Optional[np.ndarray] = None\n",
    "        self._gray_buffer2: Optional[np.ndarray] = None\n",
    "\n",
    "    def read_image(self, idx: int) -> np.ndarray:\n",
    "        \"\"\"Read and preprocess image with given index.\"\"\"\n",
    "        img_path = self.path / f\"2023_09_01_SonyRX1RM2_g201b20538_f001_{idx:04}.JPG\"\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Cannot read image {idx} at {img_path}\")\n",
    "\n",
    "        # Resize image\n",
    "        img = cv2.resize(img, None, fx=Config.SCALE, fy=Config.SCALE, \n",
    "                        interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Convert to BGRA\n",
    "        rgba = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "        rgba[:, :, 3] = 255\n",
    "        return rgba\n",
    "\n",
    "    def get_search_region(self, img: np.ndarray) -> Tuple[int, int, int, int]:\n",
    "        \"\"\"Determine the search region based on the last successful match.\"\"\"\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        if self.last_match_region is None:\n",
    "            return 0, 0, w, h\n",
    "\n",
    "        cx, cy = self.last_match_region\n",
    "        half_window = Config.SEARCH_WINDOW // 2\n",
    "        \n",
    "        # Calculate ROI with bounds checking\n",
    "        x1 = max(0, cx - half_window - Config.OVERLAP_MARGIN)\n",
    "        y1 = max(0, cy - half_window - Config.OVERLAP_MARGIN)\n",
    "        x2 = min(w, cx + half_window + Config.OVERLAP_MARGIN)\n",
    "        y2 = min(h, cy + half_window + Config.OVERLAP_MARGIN)\n",
    "        \n",
    "        return x1, y1, x2, y2\n",
    "\n",
    "    def update_last_match_region(self, matrix: np.ndarray, img_shape: Tuple[int, int]):\n",
    "        \"\"\"Update the last match region based on the transformation matrix.\"\"\"\n",
    "        h, w = img_shape[:2]\n",
    "        center = np.array([[w/2], [h/2], [1]], dtype=np.float32)\n",
    "        transformed = matrix @ center\n",
    "        # Extract scalar values using item() to avoid deprecation warning\n",
    "        self.last_match_region = (int(transformed[0].item()), int(transformed[1].item()))\n",
    "\n",
    "    def find_matches(self, img1: np.ndarray, img2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Find feature matches between two images.\"\"\"\n",
    "        # Get search region and extract ROI\n",
    "        x1, y1, x2, y2 = self.get_search_region(img1)\n",
    "        img1_roi = img1[y1:y2, x1:x2]\n",
    "\n",
    "        # Reuse grayscale buffers if possible\n",
    "        if (self._gray_buffer1 is None or \n",
    "            self._gray_buffer1.shape != img1_roi.shape[:2]):\n",
    "            self._gray_buffer1 = cv2.cvtColor(img1_roi, cv2.COLOR_BGRA2GRAY)\n",
    "        else:\n",
    "            cv2.cvtColor(img1_roi, cv2.COLOR_BGRA2GRAY, \n",
    "                        dst=self._gray_buffer1)\n",
    "\n",
    "        if (self._gray_buffer2 is None or \n",
    "            self._gray_buffer2.shape != img2.shape[:2]):\n",
    "            self._gray_buffer2 = cv2.cvtColor(img2, cv2.COLOR_BGRA2GRAY)\n",
    "        else:\n",
    "            cv2.cvtColor(img2, cv2.COLOR_BGRA2GRAY, \n",
    "                        dst=self._gray_buffer2)\n",
    "\n",
    "        # Detect and compute features\n",
    "        kp1, desc1 = self.sift.detectAndCompute(self._gray_buffer1, None)\n",
    "        kp2, desc2 = self.sift.detectAndCompute(self._gray_buffer2, None)\n",
    "\n",
    "        if not kp1 or not kp2:\n",
    "            raise ValueError(\"No features detected in one or both images\")\n",
    "\n",
    "        # Match features\n",
    "        matches = self.matcher.knnMatch(desc1, desc2, k=2)\n",
    "        good = [m for m, n in matches if m.distance < Config.MATCH_RATIO * n.distance]\n",
    "        if len(good) < 4:\n",
    "            raise ValueError(\"Not enough good matches found\")\n",
    "\n",
    "        good = sorted(good, key=lambda x: x.distance)[:int(len(good) * Config.KEEP_PERCENT)]\n",
    "\n",
    "        # Adjust keypoint coordinates\n",
    "        pts1 = np.float32([kp1[m.queryIdx].pt for m in good]) + [x1, y1]\n",
    "        pts2 = np.float32([kp2[m.trainIdx].pt for m in good])\n",
    "        \n",
    "        return pts1, pts2\n",
    "\n",
    "    def align_images(self, pts1: np.ndarray, pts2: np.ndarray, \n",
    "                    img_shape: Tuple[int, int]) -> np.ndarray:\n",
    "        \"\"\"Align images using feature matches.\"\"\"\n",
    "        matrix, inliers = cv2.estimateAffinePartial2D(\n",
    "            pts2, pts1,\n",
    "            method=cv2.RANSAC,\n",
    "            ransacReprojThreshold=Config.THRESH\n",
    "        )\n",
    "\n",
    "        if matrix is None or np.count_nonzero(inliers) < Config.MIN_INLIERS * len(pts1):\n",
    "            raise ValueError(\"Not enough inliers for alignment\")\n",
    "\n",
    "        self.update_last_match_region(matrix, img_shape)\n",
    "        return matrix\n",
    "\n",
    "    def widen_image(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Expand image canvas with padding.\"\"\"\n",
    "        h, w = img.shape[:2]\n",
    "        pad = int(Config.WIDEN * Config.SCALE)\n",
    "        canvas = np.zeros((h + pad, w + pad, 4), dtype=np.uint8)\n",
    "        offset = pad // 2\n",
    "        canvas[offset:offset + h, offset:offset + w] = img\n",
    "        return canvas\n",
    "\n",
    "    def blend_images(self, img1: np.ndarray, img2: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Blend two images using alpha channel.\"\"\"\n",
    "        result = np.zeros_like(img1)\n",
    "        a1 = img1[:, :, 3].astype(np.float32) / 255.0\n",
    "        a2 = img2[:, :, 3].astype(np.float32) / 255.0\n",
    "        a_out = a2 + a1 * (1 - a2)\n",
    "        mask = a_out > 0\n",
    "\n",
    "        for c in range(3):\n",
    "            result[mask, c] = (\n",
    "                img2[mask, c] * a2[mask] + \n",
    "                img1[mask, c] * a1[mask] * (1 - a2[mask])\n",
    "            ) / a_out[mask]\n",
    "\n",
    "        result[:, :, 3] = (a_out * 255).astype(np.uint8)\n",
    "        return result\n",
    "\n",
    "    def crop_result(self, img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Crop image to content bounds.\"\"\"\n",
    "        coords = np.argwhere(img[:, :, 3] > 0)\n",
    "        if len(coords) == 0:\n",
    "            return img\n",
    "        y1, x1 = coords.min(axis=0)\n",
    "        y2, x2 = coords.max(axis=0) + 1\n",
    "        return img[y1:y2, x1:x2].copy()\n",
    "\n",
    "    def stitch(self, start: int = 3, end: int = 21):\n",
    "        \"\"\"Stitch images in the given range.\"\"\"\n",
    "        print(f\"\\nStarting image stitching process from {start} to {end}\")\n",
    "        start_time = time()\n",
    "        result = self.read_image(start)\n",
    "        total_images = end - start - 1\n",
    "        processed = 0\n",
    "        failures = 0\n",
    "\n",
    "        for idx in range(start + 1, end):\n",
    "            try:\n",
    "                iter_start = time()\n",
    "                print(f\"\\nProcessing image {idx}/{end-1} \", end=\"\")\n",
    "\n",
    "                # Read and prepare images\n",
    "                current = self.read_image(idx)\n",
    "                current = self.widen_image(current)\n",
    "                result = self.widen_image(result)\n",
    "\n",
    "                # Align and blend\n",
    "                pts1, pts2 = self.find_matches(result, current)\n",
    "                matrix = self.align_images(pts1, pts2, current.shape)\n",
    "                aligned = cv2.warpAffine(\n",
    "                    current, matrix,\n",
    "                    (result.shape[1], result.shape[0]),\n",
    "                    flags=cv2.INTER_LINEAR,\n",
    "                    borderMode=cv2.BORDER_TRANSPARENT\n",
    "                )\n",
    "                result = self.blend_images(result, aligned)\n",
    "                result = self.crop_result(result)\n",
    "\n",
    "                # Save intermediate results\n",
    "                if idx == 20:\n",
    "                    cv2.imwrite(f\"result_{idx}.png\", result)\n",
    "                    print(f\"[Saved result_{idx}.png]\", end=\"\")\n",
    "\n",
    "                processed += 1\n",
    "                print(f\"[{time() - iter_start:.1f}s]\")\n",
    "\n",
    "            except Exception as e:\n",
    "                failures += 1\n",
    "                print(f\"\\nError at image {idx}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        total_time = time() - start_time\n",
    "        print(f\"\\nStitching completed:\")\n",
    "        print(f\"Total images processed: {processed}/{total_images} ({failures} failed)\")\n",
    "        print(f\"Total time: {total_time:.1f}s \"\n",
    "              f\"(avg {total_time/total_images:.1f}s per image)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stitcher = ImageStitcher()\n",
    "    stitcher.stitch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876639ac-0b15-43dc-8ae5-6c8af794af34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
