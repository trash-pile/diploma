{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0003fb5-bebf-41e6-9a0e-02d618bc31e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16 worker threads (all available cores)\n",
      "Search field area multiplier: 1.6x each dimension (2.56x total area)\n",
      "\n",
      "Starting image stitching process from 3 to 21\n",
      "\n",
      "Processing image 3/20 [4.5s]\n",
      "\n",
      "Processing image 4/20 [4.9s]\n",
      "\n",
      "Processing image 5/20 [5.0s]\n",
      "\n",
      "Processing image 6/20 [5.4s]\n",
      "\n",
      "Processing image 7/20 [5.6s]\n",
      "\n",
      "Processing image 8/20 [5.9s]\n",
      "\n",
      "Processing image 9/20 [6.0s]\n",
      "\n",
      "Processing image 10/20 [5.8s]\n",
      "\n",
      "Processing image 11/20 [5.9s]\n",
      "\n",
      "Processing image 12/20 [5.6s]\n",
      "\n",
      "Processing image 13/20 [6.0s]\n",
      "\n",
      "Processing image 14/20 [5.6s]\n",
      "\n",
      "Processing image 15/20 [6.0s]\n",
      "\n",
      "Processing image 16/20 [5.9s]\n",
      "\n",
      "Processing image 17/20 [5.9s]\n",
      "\n",
      "Processing image 18/20 [5.9s]\n",
      "\n",
      "Processing image 19/20 [5.9s]\n",
      "\n",
      "Processing image 20/20 [Saved result_20.png][6.8s]\n",
      "\n",
      "Stitching completed:\n",
      "Total images processed: 18/17\n",
      "Total time: 102.8s (avg 6.0s per image)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from time import time\n",
    "from typing import Tuple, Optional\n",
    "from pathlib import Path\n",
    "import numba\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    SCALE: float = 0.25\n",
    "    NFEAT: int = 100000\n",
    "    MATCH_RATIO: float = 0.7\n",
    "    KEEP_PERCENT: float = 0.75\n",
    "    THRESH: float = 250.0\n",
    "    SIFT_EDGE_THRESHOLD: float = 10.0\n",
    "    SIFT_CONTRAST_THRESHOLD: float = 0.04\n",
    "    NUM_THREADS: int = os.cpu_count() if os.cpu_count() else 4\n",
    "    SEARCH_FIELD_MULTIPLIER: float = 1.6  # Multiplier for search field size in each dimension\n",
    "                                          # Results in (SEARCH_FIELD_MULTIPLIER^2)x larger search area\n",
    "                                          # Also determines maximum canvas expansion when needed\n",
    "                                          # Must be >= 1.0\n",
    "\n",
    "class ImageStitcher:\n",
    "    def __init__(self, path: str = \"./folder2/\"):\n",
    "        self.path = Path(path)\n",
    "        \n",
    "        # Validate SEARCH_FIELD_MULTIPLIER\n",
    "        if Config.SEARCH_FIELD_MULTIPLIER < 1.0:\n",
    "            raise ValueError(\"SEARCH_FIELD_MULTIPLIER must be >= 1.0\")\n",
    "            \n",
    "        self.sift = cv2.SIFT_create(\n",
    "            nfeatures=Config.NFEAT,\n",
    "            contrastThreshold=Config.SIFT_CONTRAST_THRESHOLD,\n",
    "            edgeThreshold=Config.SIFT_EDGE_THRESHOLD\n",
    "        )\n",
    "        self.matcher = cv2.FlannBasedMatcher(\n",
    "            dict(algorithm=1, trees=5),\n",
    "            dict(checks=32)\n",
    "        )\n",
    "        self.last_match_region: Optional[Tuple[int, int]] = None\n",
    "        self._gray_buffer1: Optional[np.ndarray] = None\n",
    "        self._gray_buffer2: Optional[np.ndarray] = None\n",
    "        self._base_image_size: Optional[Tuple[int, int]] = None  # Store base image size after scaling\n",
    "        self._canvas_offset: Tuple[int, int] = (0, 0)  # Track cumulative offset from expansions\n",
    "        print(f\"Using {Config.NUM_THREADS} worker threads (all available cores)\")\n",
    "        print(f\"Search field area multiplier: {Config.SEARCH_FIELD_MULTIPLIER}x each dimension \"\n",
    "              f\"({Config.SEARCH_FIELD_MULTIPLIER**2:.2f}x total area)\")\n",
    "        self.thread_pool = ThreadPoolExecutor(max_workers=Config.NUM_THREADS)\n",
    "\n",
    "    def read_image(self, idx: int) -> np.ndarray:\n",
    "        img_path = self.path / f\"2023_09_01_SonyRX1RM2_g201b20538_f001_{idx:04}.JPG\"\n",
    "        img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, None, fx=Config.SCALE, fy=Config.SCALE,\n",
    "                        interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Store base image size if not already set\n",
    "        if self._base_image_size is None:\n",
    "            self._base_image_size = (img.shape[1], img.shape[0])  # (width, height)\n",
    "        \n",
    "        rgba = np.zeros((img.shape[0], img.shape[1], 4), dtype=np.uint8)\n",
    "        rgba[:, :, :3] = img\n",
    "        rgba[:, :, 3] = 255\n",
    "        return rgba\n",
    "\n",
    "    def get_search_region_and_expand(self, img: np.ndarray) -> Tuple[np.ndarray, Tuple[int, int, int, int], Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Calculate search region and expand image if necessary.\n",
    "        Returns expanded image, search region coordinates, and new offset.\n",
    "        Expansion is based on SEARCH_FIELD_MULTIPLIER to ensure consistency.\n",
    "        \"\"\"\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        if self.last_match_region is None:\n",
    "            self.last_match_region = (w // 2, h // 2)  # Initialize to center\n",
    "            return img, (0, 0, w, h), (0, 0)\n",
    "\n",
    "        # Get base image dimensions after scaling\n",
    "        base_w, base_h = self._base_image_size\n",
    "        \n",
    "        # Calculate desired search window dimensions\n",
    "        search_w = int(round(base_w * Config.SEARCH_FIELD_MULTIPLIER**2))\n",
    "        search_h = int(round(base_h * Config.SEARCH_FIELD_MULTIPLIER**2))\n",
    "        search_w = max(base_w, search_w)  # Ensure search region is at least base size\n",
    "        search_h = max(base_h, search_h)\n",
    "\n",
    "        # Adjust last match region for current canvas offset\n",
    "        cx, cy = self.last_match_region\n",
    "\n",
    "        # Calculate desired search region (before boundary check)\n",
    "        x1 = int(round(cx - search_w / 2))\n",
    "        y1 = int(round(cy - search_h / 2))\n",
    "        x2 = x1 + search_w\n",
    "        y2 = y1 + search_h\n",
    "\n",
    "        # Check if search region extends beyond image boundaries\n",
    "        pad_left = max(0, -x1)\n",
    "        pad_right = max(0, x2 - w)\n",
    "        pad_top = max(0, -y1)\n",
    "        pad_bottom = max(0, y2 - h)\n",
    "\n",
    "        # Maximum allowed expansion based on SEARCH_FIELD_MULTIPLIER\n",
    "        # Corrected to use multiplier^2 for consistency with search area\n",
    "        max_pad_w = int(round(base_w * Config.SEARCH_FIELD_MULTIPLIER**2))\n",
    "        max_pad_h = int(round(base_h * Config.SEARCH_FIELD_MULTIPLIER**2))\n",
    "\n",
    "        if pad_left or pad_right or pad_top or pad_bottom:\n",
    "            # Limit padding to maximum allowed\n",
    "            pad_left = min(pad_left, max_pad_w)\n",
    "            pad_right = min(pad_right, max_pad_w)\n",
    "            pad_top = min(pad_top, max_pad_h)\n",
    "            pad_bottom = min(pad_bottom, max_pad_h)\n",
    "\n",
    "            # Create new canvas with padding\n",
    "            new_w = w + pad_left + pad_right\n",
    "            new_h = h + pad_top + pad_bottom\n",
    "            canvas = np.zeros((new_h, new_w, 4), dtype=np.uint8)\n",
    "            canvas[pad_top:pad_top + h, pad_left:pad_left + w] = img\n",
    "            \n",
    "            # Update coordinates for new canvas\n",
    "            x1 += pad_left\n",
    "            x2 += pad_left\n",
    "            y1 += pad_top\n",
    "            y2 += pad_top\n",
    "            \n",
    "            result_img = canvas\n",
    "            offset = (pad_left, pad_top)\n",
    "            \n",
    "            # Update canvas offset\n",
    "            self._canvas_offset = (self._canvas_offset[0] + pad_left, \n",
    "                                 self._canvas_offset[1] + pad_top)\n",
    "        else:\n",
    "            result_img = img\n",
    "            offset = (0, 0)\n",
    "\n",
    "        # Clip search region to image boundaries\n",
    "        x1 = max(0, x1)\n",
    "        y1 = max(0, y1)\n",
    "        x2 = min(result_img.shape[1], x2)\n",
    "        y2 = min(result_img.shape[0], y2)\n",
    "\n",
    "        return result_img, (x1, y1, x2, y2), offset\n",
    "\n",
    "    def update_last_match_region(self, matrix: np.ndarray, img_shape: Tuple[int, int], \n",
    "                               offset: Tuple[int, int], crop_offset: Optional[Tuple[int, int]] = None):\n",
    "        h, w = img_shape[:2]\n",
    "        center = np.array([[w/2], [h/2], [1]], dtype=np.float32)\n",
    "        transformed = matrix @ center\n",
    "        \n",
    "        # Adjust for expansion offset\n",
    "        new_cx = int(transformed[0, 0]) + offset[0]\n",
    "        new_cy = int(transformed[1, 0]) + offset[1]\n",
    "        \n",
    "        # Adjust for cropping if applicable\n",
    "        if crop_offset:\n",
    "            new_cx -= crop_offset[0]\n",
    "            new_cy -= crop_offset[1]\n",
    "            \n",
    "        self.last_match_region = (new_cx, new_cy)\n",
    "\n",
    "    def find_matches(self, img1: np.ndarray, img2: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, Tuple[int, int]]:\n",
    "        img1, (x1, y1, x2, y2), offset = self.get_search_region_and_expand(img1)\n",
    "        \n",
    "        # Verify that slice indices are valid\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            raise ValueError(f\"Invalid search region: x1={x1}, x2={x2}, y1={y1}, y2={y2}\")\n",
    "            \n",
    "        img1_roi = img1[y1:y2, x1:x2]\n",
    "\n",
    "        if (self._gray_buffer1 is None or \n",
    "            self._gray_buffer1.shape != img1_roi.shape[:2]):\n",
    "            self._gray_buffer1 = np.empty(img1_roi.shape[:2], dtype=np.uint8)\n",
    "        if (self._gray_buffer2 is None or \n",
    "            self._gray_buffer2.shape != img2.shape[:2]):\n",
    "            self._gray_buffer2 = np.empty(img2.shape[:2], dtype=np.uint8)\n",
    "\n",
    "        futures = [\n",
    "            self.thread_pool.submit(cv2.cvtColor, img1_roi, cv2.COLOR_BGRA2GRAY, \n",
    "                                  dst=self._gray_buffer1),\n",
    "            self.thread_pool.submit(cv2.cvtColor, img2, cv2.COLOR_BGRA2GRAY, \n",
    "                                  dst=self._gray_buffer2)\n",
    "        ]\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "\n",
    "        def detect_compute(img, sift):\n",
    "            return sift.detectAndCompute(img, None)\n",
    "        \n",
    "        future_kp1 = self.thread_pool.submit(detect_compute, self._gray_buffer1, self.sift)\n",
    "        future_kp2 = self.thread_pool.submit(detect_compute, self._gray_buffer2, self.sift)\n",
    "        kp1, desc1 = future_kp1.result()\n",
    "        kp2, desc2 = future_kp2.result()\n",
    "\n",
    "        matches = self.matcher.knnMatch(desc1, desc2, k=2)\n",
    "        good = [m for m, n in matches if m.distance < Config.MATCH_RATIO * n.distance]\n",
    "        good = sorted(good, key=lambda x: x.distance)[:int(len(good) * Config.KEEP_PERCENT)]\n",
    "\n",
    "        query_idx = np.array([m.queryIdx for m in good])\n",
    "        train_idx = np.array([m.trainIdx for m in good])\n",
    "        pts1 = np.float32([kp.pt for kp in kp1])[query_idx] + [x1, y1]\n",
    "        pts2 = np.float32([kp.pt for kp in kp2])[train_idx]\n",
    "        return img1, pts1, pts2, offset\n",
    "\n",
    "    def align_images(self, pts1: np.ndarray, pts2: np.ndarray, \n",
    "                    img_shape: Tuple[int, int], offset: Tuple[int, int]) -> np.ndarray:\n",
    "        matrix, _ = cv2.estimateAffinePartial2D(\n",
    "            pts2, pts1,\n",
    "            method=cv2.RANSAC,\n",
    "            ransacReprojThreshold=Config.THRESH,\n",
    "            confidence=0.995,\n",
    "            maxIters=1000\n",
    "        )\n",
    "        return matrix\n",
    "\n",
    "    @staticmethod\n",
    "    @numba.jit(nopython=True, parallel=True)\n",
    "    def overlay_images_numba(base: np.ndarray, overlay: np.ndarray, result: np.ndarray):\n",
    "        h, w = base.shape[:2]\n",
    "        for y in numba.prange(h):\n",
    "            for x in range(w):\n",
    "                if overlay[y, x, 3] > 0:\n",
    "                    result[y, x] = overlay[y, x]\n",
    "                else:\n",
    "                    result[y, x] = base[y, x]\n",
    "\n",
    "    def overlay_images(self, base: np.ndarray, overlay: np.ndarray) -> np.ndarray:\n",
    "        result = np.zeros_like(base, dtype=np.uint8)\n",
    "        ImageStitcher.overlay_images_numba(base, overlay, result)\n",
    "        return result\n",
    "\n",
    "    def crop_result(self, img: np.ndarray) -> Tuple[np.ndarray, Tuple[int, int]]:\n",
    "        mask = img[:, :, 3] > 0\n",
    "        rows = np.any(mask, axis=1)\n",
    "        cols = np.any(mask, axis=0)\n",
    "        y1, y2 = np.where(rows)[0][[0, -1]]\n",
    "        x1, x2 = np.where(cols)[0][[0, -1]]\n",
    "        crop_offset = (x1, y1)\n",
    "        return img[y1:y2+1, x1:x2+1], crop_offset\n",
    "\n",
    "    def stitch(self, start: int = 3, end: int = 21):\n",
    "        print(f\"\\nStarting image stitching process from {start} to {end}\")\n",
    "        start_time = time()\n",
    "        result = self.read_image(start)\n",
    "        total_images = end - start - 1\n",
    "        processed = 0\n",
    "\n",
    "        for idx in range(start, end):\n",
    "            iter_start = time()\n",
    "            print(f\"\\nProcessing image {idx}/{end-1} \", end=\"\")\n",
    "\n",
    "            current = self.read_image(idx)\n",
    "            result, pts1, pts2, offset = self.find_matches(result, current)\n",
    "            matrix = self.align_images(pts1, pts2, current.shape, offset)\n",
    "            aligned = cv2.warpAffine(\n",
    "                current, matrix,\n",
    "                (result.shape[1], result.shape[0]),\n",
    "                flags=cv2.INTER_LINEAR,\n",
    "                borderMode=cv2.BORDER_TRANSPARENT\n",
    "            )\n",
    "            result = self.overlay_images(result, aligned)\n",
    "            result, crop_offset = self.crop_result(result)\n",
    "            \n",
    "            # Update last match region with both expansion and crop offsets\n",
    "            self.update_last_match_region(matrix, current.shape, offset, crop_offset)\n",
    "            \n",
    "            if idx == 20:\n",
    "                cv2.imwrite(f\"result_{idx}.png\", result)\n",
    "                print(f\"[Saved result_{idx}.png]\", end=\"\")\n",
    "\n",
    "            processed += 1\n",
    "            print(f\"[{time() - iter_start:.1f}s]\")\n",
    "\n",
    "        total_time = time() - start_time\n",
    "        print(f\"\\nStitching completed:\")\n",
    "        print(f\"Total images processed: {processed}/{total_images}\")\n",
    "        print(f\"Total time: {total_time:.1f}s \"\n",
    "              f\"(avg {total_time/total_images:.1f}s per image)\")\n",
    "\n",
    "    def __del__(self):\n",
    "        self.thread_pool.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stitcher = ImageStitcher()\n",
    "    stitcher.stitch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e0fa9-719d-4cde-bbef-cd9f20b7aab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
