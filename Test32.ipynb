{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "756e0e8e-9e68-4e93-9943-2d9737afd60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16 worker threads\n",
      "\n",
      "Starting image stitching process from 3 to 6\n",
      "Memory before starting stitch: 114.21MB\n",
      "Memory after setting initial image 3: 139.89MB\n",
      "\n",
      "Processing image 4/6\n",
      "  - Memory at start of iteration: 139.91MB\n",
      "  - Memory after reading image 4: 146.41MB\n",
      "  - Current image size: 6.44MB\n",
      "  - Memory before find_matches: 146.41MB\n",
      "  - Memory after extracting ROI: 511.54MB\n",
      "  - ROI size: 213.49MB\n",
      "  - Descriptors size (img1): 24.41MB\n",
      "  - Descriptors size (img2): 14.14MB\n",
      "  - Memory after find_matches: 31.56MB\n",
      "Adjusted scaling factor from 0.9912 to 1.0\n",
      "  - Memory after caching far tiles: 30.83MB\n",
      "  - Find matches: 25.334s\n",
      "    - Extract ROI: 0.703s\n",
      "    - Allocate buffers: 0.000s\n",
      "    - Convert to grayscale: 0.021s\n",
      "    - SIFT detection: 22.275s\n",
      "    - FLANN matching: 2.215s\n",
      "    - Filter matches: 0.012s\n",
      "    - Extract points: 0.080s\n",
      "  - Align images: 0.019s\n",
      "  - Update match region: 0.004s\n",
      "  - Cache far tiles: 0.082s\n",
      "[Total for image 4: 25.723s]\n",
      "\n",
      "Processing image 5/6\n",
      "  - Memory at start of iteration: 30.84MB\n",
      "  - Memory after reading image 5: 30.91MB\n",
      "  - Current image size: 6.44MB\n",
      "  - Memory before find_matches: 30.91MB\n",
      "  - Memory after extracting ROI: 413.48MB\n",
      "  - ROI size: 213.49MB\n",
      "  - Descriptors size (img1): 24.41MB\n",
      "  - Descriptors size (img2): 13.86MB\n",
      "  - Memory after find_matches: 25.23MB\n",
      "Adjusted scaling factor from 0.9950 to 1.0\n",
      "  - Memory after caching far tiles: 27.33MB\n",
      "  - Find matches: 37.797s\n",
      "    - Extract ROI: 0.510s\n",
      "    - Allocate buffers: 0.000s\n",
      "    - Convert to grayscale: 0.051s\n",
      "    - SIFT detection: 34.925s\n",
      "    - FLANN matching: 2.230s\n",
      "    - Filter matches: 0.008s\n",
      "    - Extract points: 0.050s\n",
      "  - Align images: 0.015s\n",
      "  - Update match region: 0.003s\n",
      "  - Cache far tiles: 0.190s\n",
      "[Total for image 5: 38.008s]\n",
      "\n",
      "Processing image 6/6\n",
      "  - Memory at start of iteration: 27.35MB\n",
      "  - Memory after reading image 6: 27.36MB\n",
      "  - Current image size: 6.44MB\n",
      "  - Memory before find_matches: 27.37MB\n",
      "  - Memory after extracting ROI: 398.89MB\n",
      "  - ROI size: 213.49MB\n",
      "  - Descriptors size (img1): 24.41MB\n",
      "  - Descriptors size (img2): 13.11MB\n",
      "  - Memory after find_matches: 29.91MB\n",
      "Adjusted scaling factor from 1.0058 to 1.0\n",
      "  - Memory after caching far tiles: 31.70MB\n",
      "  - Find matches: 19.704s\n",
      "    - Extract ROI: 0.524s\n",
      "    - Allocate buffers: 0.000s\n",
      "    - Convert to grayscale: 0.051s\n",
      "    - SIFT detection: 17.088s\n",
      "    - FLANN matching: 1.973s\n",
      "    - Filter matches: 0.010s\n",
      "    - Extract points: 0.040s\n",
      "  - Align images: 0.001s\n",
      "  - Update match region: 0.001s\n",
      "  - Cache far tiles: 0.012s\n",
      "[Total for image 6: 19.719s]\n",
      "  - Downscaled canvas size: 1044x1502\n",
      "  - Saved downscaled result_6.png\n",
      "Final memory usage: 179.71MB\n",
      "\n",
      "Stitching completed in 85.990s\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from time import time\n",
    "from typing import Tuple, Optional\n",
    "from pathlib import Path\n",
    "import numba\n",
    "from concurrent.futures import ThreadPoolExecutor, Future\n",
    "import os\n",
    "import psutil  # For memory monitoring\n",
    "\n",
    "# Configuration settings for the stitching process\n",
    "@dataclass(frozen=True)\n",
    "class Config:\n",
    "    SCALE: float = 0.20  # Initial scale for processing\n",
    "    NFEAT: int = 50000\n",
    "    MATCH_RATIO: float = 0.75\n",
    "    KEEP_PERCENT: float = 0.75\n",
    "    THRESH: float = 250.0\n",
    "    SIFT_EDGE_THRESHOLD: float = 10.0\n",
    "    SIFT_CONTRAST_THRESHOLD: float = 0.04\n",
    "    NUM_THREADS: int = os.cpu_count() if os.cpu_count() else 4\n",
    "    SEARCH_FIELD_MULTIPLIER: float = 2.4\n",
    "    DOWNSCALE_FACTOR: float = 0.5  # Downscale by 2x before saving\n",
    "\n",
    "class TileManager:\n",
    "    \"\"\"Manages a tiled representation of an image with caching to disk.\"\"\"\n",
    "    def __init__(self, tile_size=1000, cache_dir=\"cache\"):\n",
    "        self.tile_size = tile_size\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        self.tiles = {}  # (tile_x, tile_y) -> np.ndarray or None\n",
    "        self.active_tiles = set()  # Tiles with non-zero alpha\n",
    "        self.tile_bboxes = {}  # Bounding boxes within each tile\n",
    "\n",
    "    def get_tile(self, tile_x: int, tile_y: int) -> Optional[np.ndarray]:\n",
    "        \"\"\"Retrieve a tile, loading from disk if necessary.\"\"\"\n",
    "        if (tile_x, tile_y) in self.tiles:\n",
    "            return self.tiles[(tile_x, tile_y)]\n",
    "        file_path = self.cache_dir / f\"tile_{tile_x}_{tile_y}.png\"\n",
    "        if file_path.exists():\n",
    "            tile = cv2.imread(str(file_path), cv2.IMREAD_UNCHANGED)\n",
    "            self.tiles[(tile_x, tile_y)] = tile\n",
    "            return tile\n",
    "        return None\n",
    "\n",
    "    def set_tile(self, tile_x: int, tile_y: int, data: np.ndarray):\n",
    "        \"\"\"Set a tile and update its bounding box if it has non-zero alpha.\"\"\"\n",
    "        self.tiles[(tile_x, tile_y)] = data\n",
    "        mask = data[:, :, 3] > 0\n",
    "        if np.any(mask):\n",
    "            rows = np.any(mask, axis=1)\n",
    "            cols = np.any(mask, axis=0)\n",
    "            ty1, ty2 = np.where(rows)[0][[0, -1]]\n",
    "            tx1, tx2 = np.where(cols)[0][[0, -1]]\n",
    "            self.tile_bboxes[(tile_x, tile_y)] = (tx1, ty1, tx2 + 1, ty2 + 1)\n",
    "            self.active_tiles.add((tile_x, tile_y))\n",
    "        else:\n",
    "            self.tile_bboxes.pop((tile_x, tile_y), None)\n",
    "            self.active_tiles.discard((tile_x, tile_y))\n",
    "\n",
    "    def cache_tile(self, tile_x: int, tile_y: int):\n",
    "        \"\"\"Cache a tile to disk and remove it from memory.\"\"\"\n",
    "        if (tile_x, tile_y) in self.tiles:\n",
    "            tile = self.tiles[(tile_x, tile_y)]\n",
    "            if tile is not None:\n",
    "                file_path = self.cache_dir / f\"tile_{tile_x}_{tile_y}.png\"\n",
    "                cv2.imwrite(str(file_path), tile)\n",
    "                del self.tiles[(tile_x, tile_y)]\n",
    "\n",
    "    def get_region(self, x1: int, y1: int, x2: int, y2: int) -> np.ndarray:\n",
    "        \"\"\"Extract a contiguous region from the tiled image.\"\"\"\n",
    "        tile_x1 = x1 // self.tile_size\n",
    "        tile_y1 = y1 // self.tile_size\n",
    "        tile_x2 = (x2 - 1) // self.tile_size\n",
    "        tile_y2 = (y2 - 1) // self.tile_size\n",
    "        w = (tile_x2 - tile_x1 + 1) * self.tile_size\n",
    "        h = (tile_y2 - tile_y1 + 1) * self.tile_size\n",
    "        region = np.zeros((h, w, 4), dtype=np.uint8)\n",
    "        for ty in range(tile_y1, tile_y2 + 1):\n",
    "            for tx in range(tile_x1, tile_x2 + 1):\n",
    "                tile = self.get_tile(tx, ty)\n",
    "                if tile is None:\n",
    "                    tile = np.zeros((self.tile_size, self.tile_size, 4), dtype=np.uint8)\n",
    "                px = (tx - tile_x1) * self.tile_size\n",
    "                py = (ty - tile_y1) * self.tile_size\n",
    "                region[py:py + self.tile_size, px:px + self.tile_size] = tile\n",
    "        ox = x1 - tile_x1 * self.tile_size\n",
    "        oy = y1 - tile_y1 * self.tile_size\n",
    "        return region[oy:oy + (y2 - y1), ox:ox + (x2 - x1)]\n",
    "\n",
    "    def set_region(self, x1: int, y1: int, x2: int, y2: int, data: np.ndarray):\n",
    "        \"\"\"Set a region into the tiled image, updating affected tiles.\"\"\"\n",
    "        tile_x1 = x1 // self.tile_size\n",
    "        tile_y1 = y1 // self.tile_size\n",
    "        tile_x2 = (x2 - 1) // self.tile_size\n",
    "        tile_y2 = (y2 - 1) // self.tile_size\n",
    "        for ty in range(tile_y1, tile_y2 + 1):\n",
    "            for tx in range(tile_x1, tile_x2 + 1):\n",
    "                tx_start = max(x1, tx * self.tile_size)\n",
    "                ty_start = max(y1, ty * self.tile_size)\n",
    "                tx_end = min(x2, (tx + 1) * self.tile_size)\n",
    "                ty_end = min(y2, (ty + 1) * self.tile_size)\n",
    "                if tx_start < tx_end and ty_start < ty_end:\n",
    "                    tile = self.get_tile(tx, ty)\n",
    "                    if tile is None:\n",
    "                        tile = np.zeros((self.tile_size, self.tile_size, 4), dtype=np.uint8)\n",
    "                    tpx_start = tx_start - tx * self.tile_size\n",
    "                    tpy_start = ty_start - ty * self.tile_size\n",
    "                    tpx_end = tpx_start + (tx_end - tx_start)\n",
    "                    tpy_end = tpy_start + (ty_end - ty_start)\n",
    "                    dx_start = tx_start - x1\n",
    "                    dy_start = ty_start - y1\n",
    "                    dx_end = dx_start + (tx_end - tx_start)\n",
    "                    dy_end = dy_start + (ty_end - ty_start)\n",
    "                    tile[tpy_start:tpy_end, tpx_start:tpx_end] = data[dy_start:dy_end, dx_start:dx_end]\n",
    "                    self.set_tile(tx, ty, tile)\n",
    "\n",
    "    def set_large_image(self, x0: int, y0: int, large_img: np.ndarray):\n",
    "        \"\"\"Set a large image into the tiled structure at position (x0, y0).\"\"\"\n",
    "        h, w = large_img.shape[:2]\n",
    "        tile_x1 = x0 // self.tile_size\n",
    "        tile_y1 = y0 // self.tile_size\n",
    "        tile_x2 = (x0 + w - 1) // self.tile_size\n",
    "        tile_y2 = (y0 + h - 1) // self.tile_size\n",
    "        for ty in range(tile_y1, tile_y2 + 1):\n",
    "            for tx in range(tile_x1, tile_x2 + 1):\n",
    "                tx_start = max(x0, tx * self.tile_size)\n",
    "                ty_start = max(y0, ty * self.tile_size)\n",
    "                tx_end = min(x0 + w, (tx + 1) * self.tile_size)\n",
    "                ty_end = min(y0 + h, (ty + 1) * self.tile_size)\n",
    "                if tx_start < tx_end and ty_start < ty_end:\n",
    "                    lx_start = tx_start - x0\n",
    "                    ly_start = ty_start - y0\n",
    "                    lx_end = tx_end - x0\n",
    "                    ly_end = ty_end - y0\n",
    "                    tile = self.get_tile(tx, ty)\n",
    "                    if tile is None:\n",
    "                        tile = np.zeros((self.tile_size, self.tile_size, 4), dtype=np.uint8)\n",
    "                    tpx_start = tx_start - tx * self.tile_size\n",
    "                    tpy_start = ty_start - ty * self.tile_size\n",
    "                    tpx_end = tpx_start + (lx_end - lx_start)\n",
    "                    tpy_end = tpy_start + (ly_end - ly_start)\n",
    "                    tile[tpy_start:tpy_end, tpx_start:tpx_end] = large_img[ly_start:ly_end, lx_start:lx_end]\n",
    "                    self.set_tile(tx, ty, tile)\n",
    "\n",
    "    def cache_far_tiles(self, center_x: int, center_y: int, threshold: float):\n",
    "        \"\"\"Cache tiles farther than the threshold from the center.\"\"\"\n",
    "        to_cache = []\n",
    "        for (tx, ty), tile in list(self.tiles.items()):\n",
    "            if tile is not None:\n",
    "                tile_center_x = (tx + 0.5) * self.tile_size\n",
    "                tile_center_y = (ty + 0.5) * self.tile_size\n",
    "                distance = np.sqrt((tile_center_x - center_x)**2 + (tile_center_y - center_y)**2)\n",
    "                if distance > threshold:\n",
    "                    to_cache.append((tx, ty))\n",
    "        for tx, ty in to_cache:\n",
    "            self.cache_tile(tx, ty)\n",
    "\n",
    "    def get_bounding_box(self) -> Optional[Tuple[int, int, int, int]]:\n",
    "        \"\"\"Get the bounding box of all active tiles.\"\"\"\n",
    "        if not self.active_tiles:\n",
    "            return None\n",
    "        min_x = min((tx * self.tile_size + self.tile_bboxes[(tx, ty)][0]) for tx, ty in self.active_tiles)\n",
    "        min_y = min((ty * self.tile_size + self.tile_bboxes[(tx, ty)][1]) for tx, ty in self.active_tiles)\n",
    "        max_x = max((tx * self.tile_size + self.tile_bboxes[(tx, ty)][2]) for tx, ty in self.active_tiles)\n",
    "        max_y = max((ty * self.tile_size + self.tile_bboxes[(tx, ty)][3]) for tx, ty in self.active_tiles)\n",
    "        return min_x, min_y, max_x, max_y\n",
    "\n",
    "class ImageStitcher:\n",
    "    def __init__(self, path: str = \"./folder2/\"):\n",
    "        \"\"\"Initialize the ImageStitcher with a directory path.\"\"\"\n",
    "        self.path = Path(path)\n",
    "        if Config.SEARCH_FIELD_MULTIPLIER < 1.0:\n",
    "            raise ValueError(\"SEARCH_FIELD_MULTIPLIER must be >= 1.0\")\n",
    "        self.sift = cv2.SIFT_create(\n",
    "            nfeatures=Config.NFEAT,\n",
    "            contrastThreshold=Config.SIFT_CONTRAST_THRESHOLD,\n",
    "            edgeThreshold=Config.SIFT_EDGE_THRESHOLD\n",
    "        )\n",
    "        self.matcher = cv2.FlannBasedMatcher(dict(algorithm=1, trees=5), dict(checks=61))\n",
    "        self.last_match_region: Optional[Tuple[int, int]] = None\n",
    "        self._gray_buffer1: Optional[np.ndarray] = None\n",
    "        self._gray_buffer2: Optional[np.ndarray] = None\n",
    "        self._base_image_size: Optional[Tuple[int, int]] = None\n",
    "        self.tile_manager = TileManager(tile_size=1000, cache_dir=\"cache\")\n",
    "        print(f\"Using {Config.NUM_THREADS} worker threads\")\n",
    "        self.thread_pool = ThreadPoolExecutor(max_workers=Config.NUM_THREADS)\n",
    "        self.process = psutil.Process(os.getpid())\n",
    "        self.transformations = []  # List to store (matrix, image) pairs\n",
    "\n",
    "    def get_memory_usage(self) -> float:\n",
    "        \"\"\"Get current memory usage in MB.\"\"\"\n",
    "        return self.process.memory_info().rss / 1024**2\n",
    "\n",
    "    def log_memory(self, message: str):\n",
    "        \"\"\"Log memory usage with a message.\"\"\"\n",
    "        print(f\"{message}: {self.get_memory_usage():.2f}MB\")\n",
    "\n",
    "    def calculate_array_size(self, arr: np.ndarray) -> float:\n",
    "        \"\"\"Calculate the size of a numpy array in MB.\"\"\"\n",
    "        return arr.nbytes / 1024**2\n",
    "\n",
    "    def read_image(self, idx: int) -> Tuple[np.ndarray, dict]:\n",
    "        \"\"\"Read and preprocess an image from disk.\"\"\"\n",
    "        timings = {}\n",
    "        path_start = time()\n",
    "        img_path = self.path / f\"2023_09_01_SonyRX1RM2_g201b20538_f001_{idx:04}.JPG\"\n",
    "        timings['construct_path'] = time() - path_start\n",
    "        read_start = time()\n",
    "        img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "        timings['read_from_disk'] = time() - read_start\n",
    "        resize_start = time()\n",
    "        img = cv2.resize(img, None, fx=Config.SCALE, fy=Config.SCALE, interpolation=cv2.INTER_LINEAR)\n",
    "        timings['resize'] = time() - resize_start\n",
    "        if self._base_image_size is None:\n",
    "            self._base_image_size = (img.shape[1], img.shape[0])\n",
    "            if self.last_match_region is None:\n",
    "                self.last_match_region = (img.shape[1] // 2, img.shape[0] // 2)\n",
    "        rgba_start = time()\n",
    "        rgba = np.zeros((img.shape[0], img.shape[1], 4), dtype=np.uint8)\n",
    "        rgba[:, :, :3] = img\n",
    "        rgba[:, :, 3] = 255\n",
    "        timings['convert_to_rgba'] = time() - rgba_start\n",
    "        return rgba, timings\n",
    "\n",
    "    def get_search_region_and_expand(self) -> Tuple[Tuple[int, int, int, int], Tuple[int, int]]:\n",
    "        \"\"\"Define the search region in absolute coordinates.\"\"\"\n",
    "        if self.last_match_region is None:\n",
    "            raise ValueError(\"last_match_region not set\")\n",
    "        cx, cy = self.last_match_region\n",
    "        base_w, base_h = self._base_image_size\n",
    "        search_w = int(round(base_w * Config.SEARCH_FIELD_MULTIPLIER**2))\n",
    "        search_h = int(round(base_h * Config.SEARCH_FIELD_MULTIPLIER**2))\n",
    "        search_w = max(base_w, search_w)\n",
    "        search_h = max(base_h, search_h)\n",
    "        x1 = int(round(cx - search_w / 2))\n",
    "        y1 = int(round(cy - search_h / 2))\n",
    "        x2 = x1 + search_w\n",
    "        y2 = y1 + search_h\n",
    "        return (x1, y1, x2, y2), (0, 0)  # No padding with TileManager\n",
    "\n",
    "    def update_last_match_region(self, matrix: np.ndarray, img_shape: Tuple[int, int]):\n",
    "        \"\"\"Update the last match region based on the transformation.\"\"\"\n",
    "        h, w = img_shape[:2]\n",
    "        center = np.array([[w/2], [h/2], [1]], dtype=np.float32)\n",
    "        transformed = matrix @ center\n",
    "        new_cx = int(round(transformed[0, 0]))\n",
    "        new_cy = int(round(transformed[1, 0]))\n",
    "        self.last_match_region = (new_cx, new_cy)\n",
    "\n",
    "    def find_matches(self, current: np.ndarray) -> Tuple[np.ndarray, np.ndarray, Tuple[int, int], dict]:\n",
    "        \"\"\"Find feature matches using the tiled result image.\"\"\"\n",
    "        timings = {}\n",
    "        self.log_memory(\"  - Memory before find_matches\")\n",
    "        search_region, offset = self.get_search_region_and_expand()\n",
    "        x1, y1, x2, y2 = search_region\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            raise ValueError(f\"Invalid search region: x1={x1}, x2={x2}, y1={y1}, y2={y2}\")\n",
    "        roi_start = time()\n",
    "        img1_roi = self.tile_manager.get_region(x1, y1, x2, y2)\n",
    "        timings['extract_roi'] = time() - roi_start\n",
    "        self.log_memory(\"  - Memory after extracting ROI\")\n",
    "        print(f\"  - ROI size: {self.calculate_array_size(img1_roi):.2f}MB\")\n",
    "\n",
    "        buffer_start = time()\n",
    "        if self._gray_buffer1 is None or self._gray_buffer1.shape != img1_roi.shape[:2]:\n",
    "            self._gray_buffer1 = np.empty(img1_roi.shape[:2], dtype=np.uint8)\n",
    "        if self._gray_buffer2 is None or self._gray_buffer2.shape != current.shape[:2]:\n",
    "            self._gray_buffer2 = np.empty(current.shape[:2], dtype=np.uint8)\n",
    "        timings['allocate_buffers'] = time() - buffer_start\n",
    "\n",
    "        gray_start = time()\n",
    "        futures = [\n",
    "            self.thread_pool.submit(cv2.cvtColor, img1_roi, cv2.COLOR_BGRA2GRAY, dst=self._gray_buffer1),\n",
    "            self.thread_pool.submit(cv2.cvtColor, current, cv2.COLOR_BGRA2GRAY, dst=self._gray_buffer2)\n",
    "        ]\n",
    "        for future in futures:\n",
    "            future.result()\n",
    "        timings['convert_to_grayscale'] = time() - gray_start\n",
    "\n",
    "        def detect_compute(img, sift):\n",
    "            return sift.detectAndCompute(img, None)\n",
    "        sift_start = time()\n",
    "        future_kp1 = self.thread_pool.submit(detect_compute, self._gray_buffer1, self.sift)\n",
    "        future_kp2 = self.thread_pool.submit(detect_compute, self._gray_buffer2, self.sift)\n",
    "        kp1, desc1 = future_kp1.result()\n",
    "        kp2, desc2 = future_kp2.result()\n",
    "        timings['sift_detection'] = time() - sift_start\n",
    "        if desc1 is not None and desc2 is not None:\n",
    "            print(f\"  - Descriptors size (img1): {self.calculate_array_size(desc1):.2f}MB\")\n",
    "            print(f\"  - Descriptors size (img2): {self.calculate_array_size(desc2):.2f}MB\")\n",
    "\n",
    "        flann_start = time()\n",
    "        matches = self.matcher.knnMatch(desc1, desc2, k=2)\n",
    "        timings['flann_matching'] = time() - flann_start\n",
    "\n",
    "        filter_start = time()\n",
    "        good = [m for m, n in matches if m.distance < Config.MATCH_RATIO * n.distance]\n",
    "        good = sorted(good, key=lambda x: x.distance)[:int(len(good) * Config.KEEP_PERCENT)]\n",
    "        timings['filter_matches'] = time() - filter_start\n",
    "\n",
    "        points_start = time()\n",
    "        query_idx = np.array([m.queryIdx for m in good], dtype=int)\n",
    "        train_idx = np.array([m.trainIdx for m in good], dtype=int)\n",
    "        pts1 = np.float32([kp.pt for kp in kp1])[query_idx] + [x1, y1]\n",
    "        pts2 = np.float32([kp.pt for kp in kp2])[train_idx]\n",
    "        timings['extract_points'] = time() - points_start\n",
    "        return pts1, pts2, offset, timings\n",
    "\n",
    "    def align_images(self, pts1: np.ndarray, pts2: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Estimate the affine transformation between two sets of points.\"\"\"\n",
    "        matrix, _ = cv2.estimateAffinePartial2D(\n",
    "            pts2, pts1,\n",
    "            method=cv2.RANSAC,\n",
    "            ransacReprojThreshold=Config.THRESH,\n",
    "            confidence=0.999,\n",
    "            maxIters=10000\n",
    "        )\n",
    "        if matrix is not None:\n",
    "            L = matrix[:, :2]\n",
    "            s_x = np.linalg.norm(L[:, 0])\n",
    "            s_y = np.linalg.norm(L[:, 1])\n",
    "            s_avg = (s_x + s_y) / 2\n",
    "            if s_avg > 0:\n",
    "                matrix[:, :2] /= s_avg\n",
    "                print(f\"Adjusted scaling factor from {s_avg:.4f} to 1.0\")\n",
    "        return matrix\n",
    "\n",
    "    @staticmethod\n",
    "    @numba.jit(nopython=True, parallel=True)\n",
    "    def overlay_images_numba(base: np.ndarray, overlay: np.ndarray, result: np.ndarray):\n",
    "        \"\"\"Overlay two images efficiently using Numba.\"\"\"\n",
    "        h, w = base.shape[:2]\n",
    "        for y in numba.prange(h):\n",
    "            for x in range(w):\n",
    "                if overlay[y, x, 3] > 0:\n",
    "                    result[y, x] = overlay[y, x]\n",
    "                else:\n",
    "                    result[y, x] = base[y, x]\n",
    "\n",
    "    def overlay_images(self, base: np.ndarray, overlay: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Overlay one image onto another.\"\"\"\n",
    "        result = np.zeros_like(base, dtype=np.uint8)\n",
    "        self.overlay_images_numba(base, overlay, result)\n",
    "        return result\n",
    "\n",
    "    def stitch(self, start: int = 3, end: int = 6):\n",
    "        \"\"\"Stitch images, downscaling by 2x before saving to avoid memory overload.\"\"\"\n",
    "        print(f\"\\nStarting image stitching process from {start} to {end}\")\n",
    "        start_time = time()\n",
    "        self.log_memory(\"Memory before starting stitch\")\n",
    "        \n",
    "        # Load the first image\n",
    "        result, read_timings = self.read_image(start)\n",
    "        self.tile_manager.set_large_image(0, 0, result)\n",
    "        self.log_memory(f\"Memory after setting initial image {start}\")\n",
    "        self.transformations.append((np.eye(2, 3, dtype=np.float32), result))  # Identity matrix for first image\n",
    "\n",
    "        future: Optional[Future] = None\n",
    "        for idx in range(start + 1, end + 1):\n",
    "            iter_start = time()\n",
    "            print(f\"\\nProcessing image {idx}/{end}\")\n",
    "            self.log_memory(\"  - Memory at start of iteration\")\n",
    "\n",
    "            # Read the current image\n",
    "            if future is not None:\n",
    "                current, read_timings = future.result()\n",
    "            else:\n",
    "                current, read_timings = self.read_image(idx)\n",
    "            if idx < end:\n",
    "                future = self.thread_pool.submit(self.read_image, idx + 1)\n",
    "            self.log_memory(f\"  - Memory after reading image {idx}\")\n",
    "            print(f\"  - Current image size: {self.calculate_array_size(current):.2f}MB\")\n",
    "\n",
    "            # Find matches and align\n",
    "            match_start = time()\n",
    "            pts1, pts2, offset, match_timings = self.find_matches(current)\n",
    "            match_time = time() - match_start\n",
    "            self.log_memory(\"  - Memory after find_matches\")\n",
    "\n",
    "            align_start = time()\n",
    "            matrix = self.align_images(pts1, pts2)\n",
    "            align_time = time() - align_start\n",
    "\n",
    "            # Store transformation and image\n",
    "            self.transformations.append((matrix, current))\n",
    "\n",
    "            # Update match region and cache tiles\n",
    "            update_start = time()\n",
    "            self.update_last_match_region(matrix, current.shape)\n",
    "            update_time = time() - update_start\n",
    "\n",
    "            cache_start = time()\n",
    "            self.tile_manager.cache_far_tiles(self.last_match_region[0], self.last_match_region[1], 5000)\n",
    "            cache_time = time() - cache_start\n",
    "            self.log_memory(\"  - Memory after caching far tiles\")\n",
    "\n",
    "            # Log timings\n",
    "            print(f\"  - Find matches: {match_time:.3f}s\")\n",
    "            print(f\"    - Extract ROI: {match_timings['extract_roi']:.3f}s\")\n",
    "            print(f\"    - Allocate buffers: {match_timings['allocate_buffers']:.3f}s\")\n",
    "            print(f\"    - Convert to grayscale: {match_timings['convert_to_grayscale']:.3f}s\")\n",
    "            print(f\"    - SIFT detection: {match_timings['sift_detection']:.3f}s\")\n",
    "            print(f\"    - FLANN matching: {match_timings['flann_matching']:.3f}s\")\n",
    "            print(f\"    - Filter matches: {match_timings['filter_matches']:.3f}s\")\n",
    "            print(f\"    - Extract points: {match_timings['extract_points']:.3f}s\")\n",
    "            print(f\"  - Align images: {align_time:.3f}s\")\n",
    "            print(f\"  - Update match region: {update_time:.3f}s\")\n",
    "            print(f\"  - Cache far tiles: {cache_time:.3f}s\")\n",
    "            print(f\"[Total for image {idx}: {time() - iter_start:.3f}s]\")\n",
    "\n",
    "        # Final downscaling and saving\n",
    "        if self.transformations:\n",
    "            # Compute full-size bounding box\n",
    "            min_x, min_y, max_x, max_y = self.tile_manager.get_bounding_box()\n",
    "            for matrix, current in self.transformations[1:]:  # Skip first image already in tile_manager\n",
    "                h, w = current.shape[:2]\n",
    "                pts = np.array([[0,0], [w,0], [w,h], [0,h]], dtype=np.float32)\n",
    "                transformed = cv2.transform(pts[None, :, :], matrix)[0]\n",
    "                min_x = min(min_x, int(np.floor(transformed[:,0].min())))\n",
    "                min_y = min(min_y, int(np.floor(transformed[:,1].min())))\n",
    "                max_x = max(max_x, int(np.ceil(transformed[:,0].max())))\n",
    "                max_y = max(max_y, int(np.ceil(transformed[:,1].max())))\n",
    "\n",
    "            # Create downscaled canvas (2x smaller)\n",
    "            downscale = Config.DOWNSCALE_FACTOR  # 0.5\n",
    "            canvas_width = int((max_x - min_x) * downscale)\n",
    "            canvas_height = int((max_y - min_y) * downscale)\n",
    "            canvas = np.zeros((canvas_height, canvas_width, 4), dtype=np.uint8)\n",
    "            print(f\"  - Downscaled canvas size: {canvas_width}x{canvas_height}\")\n",
    "\n",
    "            # Warp and overlay each image onto the downscaled canvas\n",
    "            for matrix, current in self.transformations:\n",
    "                # Adjust transformation for downscaling and offset\n",
    "                M_downscaled = matrix.copy()\n",
    "                M_downscaled[0, 2] = (M_downscaled[0, 2] - min_x) * downscale\n",
    "                M_downscaled[1, 2] = (M_downscaled[1, 2] - min_y) * downscale\n",
    "                M_downscaled[0, 0] *= downscale\n",
    "                M_downscaled[0, 1] *= downscale\n",
    "                M_downscaled[1, 0] *= downscale\n",
    "                M_downscaled[1, 1] *= downscale\n",
    "\n",
    "                # Warp the image directly onto the canvas\n",
    "                aligned = cv2.warpAffine(\n",
    "                    current, M_downscaled,\n",
    "                    (canvas_width, canvas_height),\n",
    "                    flags=cv2.INTER_LINEAR,\n",
    "                    borderMode=cv2.BORDER_TRANSPARENT\n",
    "                )\n",
    "\n",
    "                # Overlay onto the canvas\n",
    "                canvas = self.overlay_images(canvas, aligned)\n",
    "\n",
    "            # Save the downscaled result\n",
    "            cv2.imwrite(f\"result_{end}.png\", canvas)\n",
    "            print(f\"  - Saved downscaled result_{end}.png\")\n",
    "\n",
    "        total_time = time() - start_time\n",
    "        self.log_memory(\"Final memory usage\")\n",
    "        print(f\"\\nStitching completed in {total_time:.3f}s\")\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Shutdown the thread pool.\"\"\"\n",
    "        self.thread_pool.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    stitcher = ImageStitcher()\n",
    "    stitcher.stitch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b1588-331b-437e-b5e5-d276db2dbb64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
